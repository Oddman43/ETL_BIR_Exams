{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "56vKIohe8Jou",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Extraction\n",
    "Using the library pypdf extract the text from the exam that it is a pdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kRORmWM8Joy"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8DpYYll8Joz",
    "outputId": "40cac5b3-1153-431b-f780-201aa62b5813"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting year and type of exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the expected total number of rows based in the number of questions and options per year using the following criteria:\n",
    "* From 2024 to 2021 = 210 questions and 4 options\n",
    "* From 2020 to 2019 = 185 questions and 4 options\n",
    "* From 2018 to 2015 = 235 questions and 4 options\n",
    "* From 2014 to 2012 = 235 questions and 5 options\n",
    "* From 2011 to 2004 = 260 questions and 5 options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_rows(year: int, topic: str) -> tuple:\n",
    "    info_year_dict: dict = {\n",
    "        2011: [260, 5],\n",
    "        2014: [235, 5],\n",
    "        2018: [235, 4],\n",
    "        2020: [185, 4],\n",
    "        2021: [210, 4],\n",
    "    }\n",
    "    save_name_dict: dict = {\n",
    "        \"BIOLOGÍA\": \"bir\",\n",
    "        \"FARMACIA\": \"fir\",\n",
    "        \"QUÍMICA\": \"qir\",\n",
    "        \"MEDICINA\": \"mir\",\n",
    "    }\n",
    "    max_rows: int = 0\n",
    "    num_questions: int = 0\n",
    "    for target_year, info_list in info_year_dict.items():\n",
    "        if year <= target_year:\n",
    "            max_rows = (info_list[0] * info_list[1]) + info_list[0]\n",
    "            num_questions = info_list[1]\n",
    "            break\n",
    "    if year >= 2021:\n",
    "        max_rows = 1050\n",
    "        num_questions = 4\n",
    "    return max_rows, f\"clean_{save_name_dict[topic]}_{year}.csv\", num_questions, save_name_dict[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year: int = ...\n",
    "topic: str = \"BIOLOGÍA\" # BIOLOGÍA, FARMACIA, QUÍMICA, MEDICINA\n",
    "total_num_rows, save_format, num_questions, sql_exam_name = compute_expected_rows(year, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1Kjq5ue8Jo1"
   },
   "source": [
    "## Extracting Questions from Pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB4M4yfr8Jo3"
   },
   "outputs": [],
   "source": [
    "path: str = f\"../data/raw/type_1/Raw_Cuaderno_{year}_{topic}_0_C.pdf\"\n",
    "with PdfReader(path) as pdf_file:\n",
    "    full_text = []\n",
    "    for n in range(2, len(pdf_file.pages)):\n",
    "        page = pdf_file.pages[n]\n",
    "        text: str = page.extract_text()\n",
    "        full_text.extend(text.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj02oBi18Jo4"
   },
   "source": [
    "Creating a Data Frame of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XCQUVcG08Jo5",
    "outputId": "ebef165a-03b6-4be2-c63f-f2ac6cadf760"
   },
   "outputs": [],
   "source": [
    "exam_df = pd.DataFrame(full_text, columns=[\"text\"])\n",
    "exam_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBhc5aFQ8Jo6"
   },
   "source": [
    "## Extracting Answers from .tsv file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "O1ouB9mQ8Jo7",
    "outputId": "70b7615d-9c90-4f2d-b9e1-a5c86b507ef6"
   },
   "outputs": [],
   "source": [
    "answers_df = pd.read_table(f\"../data/raw/type_1/Raw_Cuaderno_{year}_{topic}_0_C_Respuestas.tsv\")\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFFlTADP8Jo7"
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QavIIOK8Jo7"
   },
   "source": [
    "Removing rows containing \"Página\" and rows that have empty spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = exam_df[~exam_df[\"text\"].str.contains(\"Página\")]\n",
    "exam_df = exam_df[\"text\"].str.strip()\n",
    "exam_df = exam_df.replace(\"\", np.nan)\n",
    "exam_df = exam_df.dropna()\n",
    "exam_df = exam_df.reset_index(drop=True)\n",
    "exam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcition to join the lines \n",
    "* Checks if a line ends with \"-\" meaning that the word is truncated, so it removes the last caracter, appends the line below and deletes the appended line \n",
    "* Checks if the following line the the first caracter can be converted into an integer, meaning that it is either a Question or an option, and proceds to append the line below and deletes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYZHjn_C8Jo8"
   },
   "outputs": [],
   "source": [
    "def process_multi_line_str(df):\n",
    "    i = 0\n",
    "    while i < len(df) - 1:\n",
    "        line = df.iloc[i]\n",
    "        if i < len(df) -1  and line.endswith(\"-\"):\n",
    "            df.iloc[i] = df.iloc[i][:-1] + df.iloc[i + 1]\n",
    "            df = df.drop(i + 1)\n",
    "            df = df.reset_index(drop=True)\n",
    "        else:\n",
    "            i += 1\n",
    "    n = 0\n",
    "    while n < len(df) -1:\n",
    "        if n + 1 < len(df):\n",
    "            try:\n",
    "                int(df.iloc[n + 1][0:1])\n",
    "                n += 1\n",
    "            except ValueError:\n",
    "                df.iloc[n] = df.iloc[n] + \" \" + df.iloc[n + 1]\n",
    "                df = df.drop(n +1)\n",
    "                df = df.reset_index(drop= True)\n",
    "        else:\n",
    "            break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2v6dmQuM8_v1",
    "outputId": "215f5328-a43d-4bbb-f221-fba6fc10a5c1"
   },
   "outputs": [],
   "source": [
    "exam_df_concat = process_multi_line_str(exam_df)\n",
    "exam_df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the rows that do not end in \".\" or \":\" to fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_incorrect_expected = len(exam_df_concat) - total_num_rows\n",
    "num_rows_incorrect = exam_df_concat[~exam_df_concat.str.endswith((\".\", \":\"))].count()\n",
    "id_rows_incorrect = exam_df_concat[~exam_df_concat.str.endswith((\".\", \":\"))].index.to_list()\n",
    "print(f\"Number of expected incorrect rows = {num_rows_incorrect_expected}\")\n",
    "print(f\"Number of rows not ending with '.' of ':' = {num_rows_incorrect}\")\n",
    "print(id_rows_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows_incorrrect(wrong_id: list, df):\n",
    "    for wid in wrong_id:\n",
    "        print(f\"Id to fix {wid}:\")\n",
    "        print(df.iloc[wid -2: wid +3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_incorrect(num_row, df):\n",
    "    num_row = sorted(num_row, reverse=True)\n",
    "    for n in num_row:\n",
    "        df.iloc[n] = df.iloc[n] + df.iloc[n + 1]\n",
    "        df = df.drop(n + 1)\n",
    "        df = df.reset_index(drop= True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of incorrect rows is the same as expected call fix_incorrect and display num of rows to check if it worked\n",
    "If there are more or less number of incorrect rows print +-3 rows and add to rows_fix the id of the rows to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_rows_incorrect_expected == num_rows_incorrect:\n",
    "    exam_df_fixed = fix_incorrect(id_rows_incorrect, exam_df_concat)\n",
    "    df_correct_rows = len(exam_df_fixed) == num_rows_incorrect_expected\n",
    "else:\n",
    "    print_rows_incorrrect(id_rows_incorrect, exam_df_concat)\n",
    "    raise Warning(\"More incorrect rows that expected, uncomment the lines below and add ids to the list, and comment this line\")\n",
    "    # rows_fix = []\n",
    "    # exam_df_fixed = fix_incorrect(rows_fix, exam_df_concat)\n",
    "print(f\"Correct number of rows = {total_num_rows}\")\n",
    "print(exam_df_fixed.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df_fixed = exam_df_fixed.to_frame()\n",
    "groups = pd.Series((exam_df_fixed.index // num_questions+1) +1)\n",
    "exam_df_fixed[\"group\"] = groups  \n",
    "exam_df_fixed[\"option_num\"] = exam_df_fixed.groupby(\"group\").cumcount() + 1\n",
    "exam_df_pivot = exam_df_fixed.pivot(index=\"group\", columns=\"option_num\", values=\"text\")\n",
    "exam_df_pivot = exam_df_pivot.reset_index()\n",
    "\n",
    "key_list: list = [x for x in range(1, num_questions+2, 1)]\n",
    "val_list: list = [\"Question\"] + [f\"Option_{x}\" for x in range(1, 4 + 1, 1)]\n",
    "\n",
    "exam_df_pivot = exam_df_pivot.rename_axis(None, axis=1).rename(columns=dict(zip(key_list, val_list)))\n",
    "exam_df_pivot = exam_df_pivot.drop(columns=[\"group\"])\n",
    "\n",
    "exam_df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_col = [\"V0\", \"RC\"]\n",
    "\n",
    "duplicate_cols = [\"V0.1\", \"RC.1\", \"V0.2\", \"RC.2\", \"V0.3\", \"RC.3\", \"V0.4\", \"RC.4\"]\n",
    "\n",
    "answers_df_list = [answers_df[original_col]]\n",
    "\n",
    "for i in range(0, len(duplicate_cols), 2):\n",
    "    pair_cols = duplicate_cols[i:i+2]\n",
    "    df_pair_col = answers_df[pair_cols].rename(columns={pair_cols[0]: \"V0\", pair_cols[1]: \"RC\"})\n",
    "    answers_df_list.append(df_pair_col)\n",
    "\n",
    "answers_df_clean = pd.concat(answers_df_list, ignore_index=True)\n",
    "\n",
    "print(answers_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.concat([exam_df_pivot, answers_df_clean], axis=1)\n",
    "clean_df = clean_df.drop(columns=[\"V0\"])\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the rows with null values in RC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_df[clean_df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling null values with 0 and printing the sum of null values to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_2 = clean_df.fillna(0)\n",
    "clean_df_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Datatype of RC from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_2[\"RC\"] = clean_df_2[\"RC\"].astype(int)\n",
    "clean_df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_2[\"year\"] = year\n",
    "\n",
    "clean_df_2.to_csv(\"data/clean_bir_2024.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing into SQL db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path: str = \"../data/clean/bir_warehouse.db\"\n",
    "\n",
    "query_question: str = \"\"\"\n",
    "INSERT INTO questions (exam_year, exam_subject, question) \n",
    "VALUES((SELECT id_year FROM year WHERE year_name = ?),\n",
    "    (SELECT id_type FROM exam WHERE exam_type = ?),\n",
    "    ?);\n",
    "\"\"\"\n",
    "\n",
    "query_options: str = \"\"\"\n",
    "INSERT INTO questions_options (question_id, option_num, option_text, is_correct)\n",
    "VALUES((SELECT id FROM questions WHERE question = ?),\n",
    "    ?,\n",
    "    ?,\n",
    "    ?)\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(db_path) as bir_warehouse:\n",
    "    cur = bir_warehouse.cursor()\n",
    "    for question in clean_df_2.itertuples():\n",
    "        cur.execute(query_question, (str(question[7]), sql_exam_name, question[1]))\n",
    "        bir_warehouse.commit()\n",
    "        for n, option in enumerate(question[2:6]):\n",
    "            cur.execute(query_options, (question[1], n+1, option, n+1 == question[6]))\n",
    "            bir_warehouse.commit()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bir_etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
